#Overview
This project creates, but does not provision, an [AWS](http://aws.amazon.com/) environment suitable for running a private 
[Docker Registry]().

#Prerequisites

* [Terraform](https://terraform.io/) installed and working
* Development and testing was done on [Ubuntu Linux](http://www.ubuntu.com/)
* [SSH](http://www.openssh.com/) installed and working
* The environment variable `AWS_ACCESS_KEY_ID` set to your AWS Access Key ID 
* The environment variable `AWS_SECRET_ACCESS_KEY` set to your AWS Secret Access Key
* An existing [AWS SSH Key Pair](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html)

#Building
This project is a collection of data files consumed by Terraform so there is nothing to build. 

#Installation
You need to export your AWS key information to the environment so that Terraform can pick them up.  Typically, this is 
done via a simple export command.

* `export AWS_ACCESS_KEY_ID=AAAAAAAAAAAAAAAAAAAA`
* `export AWS_SECRET_ACCESS_KEY=AAAAAAAAAAAAAAAAAAAA`

You also need to have access to the private half of the AWS SSH key pair.  The file needs to be set to the correct permissions or 
SSH will refuse to run.  Typically this is done via the `chmod` command: `chmod 0400 private-half.pem`.  The key should be 
available as part of this source set and is named `asgard-lite-test.pem`.  Again, double check the permission bits before trying 
to connect to an instance.

If you want to use a different key pair, you'll need to edit the `variables.tf` and adjust the `key_name` variable to use your SSH Key 
Pair name.  You also need to adjust the `key_path` variable to point to the private half of the SSH key pair.

#Tips and Tricks

##Creating The Virtual Hardware
To create a new environment, run `./create.sh` and you should have a new VPC with EC2 instances running in multiple availability zones.
Terraform keeps track of the current state of the AWS assets it manages so it is **very important to commit and push any changes to 
Git** after any changes have been made.  Otherwise, Terraform will get confused when the next person clones this repository and tries 
to apply any changes.

##Verifying The Setup
Open the AWS console and grab the public ip address of the new EC2 instance and then run `./ssh-into-instance.sh` giving it the ip address 
as an argument.  If everything is correct, you should be ssh'ed into your newly created box.

##Start Over
If there is an error with configuration that prevents Terraform from completing its mission, run `./destroy.sh` to remove any assets that 
have been created.  You don't want to get charged for assets that you are not going to use! Alternatively, you can use the AWS console to 
destroy the assets but you are more likely to forget something and end up getting charged for an orphaned asset. **Please remember that the 
storage assets will be destroyed and all your data will be lost.** You have been warned.

##The Virtual Private Cloud (VPC)
All the assets are placed within a VPC so as to isolate it from other installations.  Only one availability zone is used since 
this configuration is not highly available. 

Each subnet is color coded to make troubleshooting a bit easier.  Where appropriate, assets are tagged using the color code so 
can quickly know which subnet and AZ an asset resides in.

* first AZ = Blue
* second AZ = Green
* third AZ = Red
* fourth AZ = White
* fifth AZ = Orange
* sixth AZ = Black

*NOTE:* many regions only have 2 or 3 AZs so not all colors are used.

#Troubleshooting

##Terraform Version
Easily, the largest cause of problems is that an older version of Terraform is being used.  Terraform is constantly being updated to keep 
up with AWS and you need to ensure you have the most current version installed.  Unfortunately, Terraform's error message won't give you 
a clue that  you are running an old version of the tool.

##Use Linux
Development and testing of this plan was done using Ubuntu linux.  Trying to make it work on Windows is possible but you may 
run into problems that don't appear in Linux.

##Asset Tagging
Following Amazon's advice, all generated assets are tagged such that it should be easy to identify which assets were generated by this 
plan and those that were not.  An example of some tags that are applied to an EC2 asset include:

* Managed-By: Managed By Terraform
* Name: Registry Blue
* Purpose: experimentation 
* Realm: Docker Testing

The `Managed-By` indicates that the asset was created by Terraform and not by hand.  The `Name` tag is the standard AWS tag giving the 
asset a unique name.  Notice the use of the color `Blue` in the name?  Each availability zone is assigned a color which allows you to 
identify which AZ the asset resides in.  The `Realm` is a logical grouping of all the generated assets.  In the above example, all the 
assets exist solely for experimentation.  The `Purpose` is a refinement of the `Realm` where we indicate what type of testing we are doing.
In this case, we are doing general QA but we could have tags for penetration testing, load testing, etc.


#License and Credits
This project operates under the Apache license.

#List of Changes
